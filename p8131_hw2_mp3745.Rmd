---
title: "p8105_hw3_mp3745"
author: "Matthew Parker"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## PROBLEM 1
### i)

Create dataframe
```{r}
# Covariates
dose = 0:4

# Response
resp = tibble(
  num_dead = c(2, 8, 15, 23, 27),
  num_total = 30 - num_dead
) %>% 
  as.matrix() 
```

Logistic models with grouped data (get estimate of beta and deviance)
```{r}
# Logit
fit_logit = 
  glm(resp ~ dose, 
      family = binomial(link = 'logit'))

summary(fit_logit) 


# Probit
fit_probit = 
  glm(resp ~ dose, 
      family = binomial(link = 'probit'))

summary(fit_probit)


# cloglog
fit_cloglog = 
  glm(resp ~ dose, 
      family = binomial(link = 'cloglog'))

summary(fit_cloglog)
```

Confidence intervals
```{r}
# logit
ci_logit = fit_logit %>% 
  broom::tidy() %>% 
  mutate(
    lower = estimate - 1.96 * std.error,
    upper = estimate + 1.96 * std.error
  )

# probit
ci_probit = fit_probit %>% 
  broom::tidy() %>% 
  mutate(
    lower = estimate - 1.96 * std.error,
    upper = estimate + 1.96 * std.error
  )

# cloglog
# probit
ci_cloglog = fit_cloglog %>% 
  broom::tidy() %>% 
  mutate(
    lower = estimate - 1.96 * std.error,
    upper = estimate + 1.96 * std.error
  )
```

Prob of dying given x = 0.01
```{r}
# value to predict
newdata = data.frame(
  dose = 0.01
)

# logit
predict(fit_logit, newdata = newdata, type = "response")

# probit
predict(fit_probit, newdata = newdata, type = "response")

# cloglog
predict(fit_cloglog, newdata = newdata, type = "response")

```


### ii)

#### logit
```{r}
# coefficients
logit_beta0 = fit_logit$coefficients[1]
logit_beta1 = fit_logit$coefficients[2]

# fisher information inverse
logit_betacov = vcov(fit_logit) 

# point estimate of ln(LD50)
logit_x0fit = -logit_beta0/logit_beta1

# point estimate of LD50
exp(logit_x0fit) 

# asymptotic variance
logit_varx0 = logit_betacov[1,1]/(logit_beta1^2) + logit_betacov[2,2]*(logit_beta0^2)/(logit_beta1^4) -
              2*logit_betacov[1,2]*logit_beta0/(logit_beta1^3)

# point estimate and se for ln(dose)
c(logit_x0fit, sqrt(logit_varx0))

# 95% CI for LD50
exp((logit_x0fit + c(qnorm(0.025), -qnorm(0.025))*sqrt(logit_varx0))) 
```

The point estimate for LD50 is `r exp(logit_x0fit)` with a 95% CI of (`r exp(logit_x0fit + qnorm(0.025)*sqrt(logit_varx0))`, `r exp(logit_x0fit - qnorm(0.025)*sqrt(logit_varx0))`)


#### Probit
```{r}
# coefficients
probit_beta0 = fit_probit$coefficients[1]
probit_beta1 = fit_probit$coefficients[2]

# fisher information inverse
probit_betacov = vcov(fit_probit) 

# point estimate of ln(LD50)
probit_x0fit = -probit_beta0/probit_beta1

# point estimate of LD50
exp(probit_x0fit) 

# asymptotic variance
probit_varx0 = probit_betacov[1,1]/(probit_beta1^2) + probit_betacov[2,2]*(probit_beta0^2)/(probit_beta1^4) -
              2*probit_betacov[1,2]*probit_beta0/(probit_beta1^3)

# point estimate and se for ln(dose)
c(probit_x0fit, sqrt(probit_varx0))

# 95% CI for LD50
exp((probit_x0fit + c(qnorm(0.025), -qnorm(0.025))*sqrt(probit_varx0))) 
```

The point estimate for LD50 is `r exp(probit_x0fit)` with a 95% CI of (`r exp(probit_x0fit + qnorm(0.025)*sqrt(probit_varx0))`, `r exp(probit_x0fit - qnorm(0.025)*sqrt(probit_varx0))`)


#### Cloglog
```{r}
# coefficients
cloglog_beta0 = fit_cloglog$coefficients[1]
cloglog_beta1 = fit_cloglog$coefficients[2]

# fisher information inverse
cloglog_betacov = vcov(fit_cloglog) 

# point estimate of ln(LD50)
cloglog_x0fit = (log(-log(0.5)) - cloglog_beta0)/cloglog_beta1

# point estimate of LD50
exp(cloglog_x0fit) 

# asymptotic variance
cloglog_varx0 = cloglog_betacov[1,1]/(cloglog_beta1^2) + 
              cloglog_betacov[2,2]*((cloglog_beta0 - log(-log(0.5)))^2)/(cloglog_beta1^4) -
              2*cloglog_betacov[1,2]*(cloglog_beta0 - log(-log(0.5)))/(cloglog_beta1^3)

# point estimate and se for ln(dose)
c(cloglog_x0fit, sqrt(cloglog_varx0))

# 95% CI for LD50
exp((cloglog_x0fit + c(qnorm(0.025), -qnorm(0.025))*sqrt(cloglog_varx0))) 
```

The point estimate for LD50 is `r exp(cloglog_x0fit)` with a 95% CI of (`r exp(cloglog_x0fit + qnorm(0.025)*sqrt(cloglog_varx0))`, `r exp(cloglog_x0fit - qnorm(0.025)*sqrt(cloglog_varx0))`)



## Problem 2

Enter in the data
```{r}
prob2_data = tibble(
  amount = seq(from = 10000, to = 90000, by = 5000),
  offers = c(4, 6, 10, 12, 39, 36, 22, 14, 10, 12, 8, 9, 3, 1, 5, 2, 1),
  enrolls = c(0, 2, 4, 2, 12, 14, 10, 7, 5, 5, 3, 5, 2, 0, 4, 2, 1),
  non_enrolls = offers - enrolls
)

# Predictor
amount = prob2_data %>% 
  select(amount) %>% 
  as.matrix()

# Response
enrolls = prob2_data %>% 
  select(enrolls, non_enrolls) %>% 
  as.matrix()
```

## i)

Logistic model
```{r}
prob2_fit = 
  glm(enrolls ~ amount, 
      family = binomial(link = 'logit'))

summary(prob2_fit) 
```

Check goodness of fit
```{r}
# Deviance
prob2_dev = prob2_fit$deviance

# compare with chisq(17-2)
fit_pval = 1 - pchisq(prob2_dev, 15) # fit is not good, later will see why (over dispersion; lack of covariate)
```

It looks like this model may do a good job of fitting the data. The p-value from the deviance test for goodness of fit is `r fit_pval` > 0.05. This means we fail to reject the null hypothesis of the model being a good fit.


## ii)
Get 95% confidence interval
```{r}
# Tidy output
prob2_fit_tidy = 
  prob2_fit %>% 
  broom::tidy()

# 95% CI
ci_amount = prob2_fit_tidy %>% 
  mutate(
    lower = estimate - 1.96 * std.error,
    upper = estimate + 1.96 * std.error
  ) %>% 
  filter(term == "amount") %>% 
  select(estimate, lower, upper)
```

`r ci_amount %>% select(estimate)` is the log odds ratio of enrollment per increase of $5,000 in scholarship amount. The 95% CI is (`r ci_amount %>% select(lower)`, `r ci_amount %>% select(upper)`).


## iii)











